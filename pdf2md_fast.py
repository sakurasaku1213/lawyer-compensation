# pdf2md_fast.py (Streamlit GUIç‰ˆ) - è¶…é«˜é€ŸåŒ–CPUç‰¹åŒ–
# ==============================================================================
# ğŸš€ ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
#   pip install "pymupdf<1.25" streamlit yomi-toku concurrent-futures threadpoolctl
#   # CPUç‰¹åŒ–ã§æœ€å¤§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ | ä¸¦åˆ—å‡¦ç† | é«˜é€ŸOCR
# ==============================================================================
import os, sys, json, hashlib, shutil, subprocess, tempfile, time
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing as mp
from functools import partial
import threading

import fitz                # PyMuPDF
import streamlit as st
import tkinter as tk
from tkinter import filedialog

# CPUæœ€é©åŒ–è¨­å®š
os.environ["OMP_NUM_THREADS"] = str(mp.cpu_count())
os.environ["OPENBLAS_NUM_THREADS"] = str(mp.cpu_count())

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="PDFâ†’Markdown è¶…é«˜é€Ÿå¤‰æ›",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========================================= é«˜é€ŸåŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========================================

@st.cache_data
def sha256_cached(file_path_str: str) -> str:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
    fp = Path(file_path_str)
    h = hashlib.sha256()
    with fp.open("rb") as f:
        for chunk in iter(lambda: f.read(1 << 20), b""):
            h.update(chunk)
    return h.hexdigest()

def sha256(fp: Path) -> str:
    """é«˜é€Ÿãƒãƒƒã‚·ãƒ¥è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
    return sha256_cached(str(fp))

# ========================================= é«˜é€Ÿãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º =========================================

_MIN_CHARS = 30

def has_text_layer(page: fitz.Page, min_chars: int = _MIN_CHARS) -> bool:
    """ãƒ†ã‚­ã‚¹ãƒˆå±¤ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
    try:
        text = page.get_text()
        return len(text.strip()) >= min_chars
    except:
        return False

def page_to_md_fast(page: fitz.Page) -> str:
    """é«˜é€ŸMarkdownå¤‰æ›ï¼ˆæœ€é©åŒ–æ¸ˆã¿ï¼‰"""
    try:
        # é«˜é€Ÿãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        text_dict = page.get_text("dict", flags=fitz.TEXTFLAGS_TEXT)
        if not text_dict or "blocks" not in text_dict:
            return ""
        
        lines = []
        for block in text_dict["blocks"]:
            if block.get("type") != 0:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ã¿
                continue
            
            for line in block.get("lines", []):
                spans = line.get("spans", [])
                if not spans:
                    continue
                
                span = spans[0]
                text = span.get("text", "").rstrip()
                if text:
                    lines.append({
                        "size": span.get("size", 12),
                        "text": text
                    })
        
        if not lines:
            return ""
        
        # ã‚µã‚¤ã‚ºåˆ¥è¦‹å‡ºã—åˆ¤å®šï¼ˆé«˜é€ŸåŒ–ï¼‰
        sizes = sorted(set(l["size"] for l in lines), reverse=True)
        h1_size = sizes[0] if sizes else 12
        h2_size = sizes[1] if len(sizes) > 1 else h1_size
        
        # Markdownå¤‰æ›ï¼ˆæœ€é©åŒ–ï¼‰
        md_lines = []
        bullet_prefixes = ("â€¢", "ãƒ»", "ã€‡", "â—¯", "-", "â€•", "â€“", "*")
          for line in lines:
            txt = line["text"]
            if not txt:
                continue
                
            size = line["size"]
            if size >= h1_size:
                md_lines.append(f"# {txt}")
            elif size >= h2_size:
                md_lines.append(f"## {txt}")
            elif txt.lstrip().startswith(bullet_prefixes):
                clean_text = txt.lstrip('â€¢ãƒ»ã€‡â—¯-â€“â€•* ')
                md_lines.append(f"- {clean_text}")
            else:
                md_lines.append(txt)
        
        return "\n".join(md_lines)
        
    except Exception as e:
        st.warning(f"ãƒšãƒ¼ã‚¸ã®Markdownå¤‰æ›ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
page_to_md = page_to_md_fast

# ========================================= è¶…é«˜é€ŸOCRå‡¦ç† =========================================

def export_pages_as_png_parallel(doc: fitz.Document, indices: List[int], 
                                dpi: int = 150, outdir: Path = None, 
                                max_workers: int = None) -> List[Path]:
    """ä¸¦åˆ—ç”»åƒã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆDPIä¸‹ã’ã¦é«˜é€ŸåŒ–ï¼‰"""
    if outdir is None:
        try:
            outdir = Path(tempfile.mkdtemp(prefix="pdf2md_png_fast_"))
        except Exception as e:
            st.error(f"PNGã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå¤±æ•—: {e}")
            return []
    else:
        outdir = Path(outdir)
    
    try:
        outdir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        st.error(f"PNGã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå…ˆä½œæˆå¤±æ•—: {e}")
        return []
    
    if max_workers is None:
        max_workers = min(mp.cpu_count(), len(indices))
    
    def export_single_page(page_idx: int) -> Optional[Path]:
        try:
            page = doc.load_page(page_idx)
            # é«˜é€ŸåŒ–: ã‚ˆã‚Šå°ã•ãªDPIã¨åœ§ç¸®ç”»åƒ
            pix = page.get_pixmap(dpi=dpi, alpha=False)
            png_path = outdir / f"page_{page_idx+1}.png"
            pix.save(png_path)
            pix = None  # ãƒ¡ãƒ¢ãƒªè§£æ”¾
            return png_path
        except Exception as e:
            st.warning(f"ãƒšãƒ¼ã‚¸ {page_idx+1} ã®PNGã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
            return None
    
    png_paths = []
    # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§ä¸¦åˆ—å‡¦ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_idx = {executor.submit(export_single_page, idx): idx for idx in indices}
        for future in as_completed(future_to_idx):
            result = future.result()
            if result:
                png_paths.append(result)
    
    return sorted(png_paths)  # ãƒšãƒ¼ã‚¸é †åºã‚’ä¿æŒ

def run_yomitoku_fast(png_paths: List[Path], device: str = "cpu") -> Dict[int, str]:
    """YomiTokué«˜é€Ÿå®Ÿè¡Œï¼ˆCPUæœ€é©åŒ–ï¼‰"""
    if not png_paths:
        return {}
    
    md_by_page = {}
    
    try:
        with tempfile.TemporaryDirectory(prefix="yomitoku_fast_out_") as ocr_output_tmpdir_str, \
             tempfile.TemporaryDirectory(prefix="yomitoku_fast_in_") as input_img_tmpdir_str:
            
            ocr_output_tmpdir_path = Path(ocr_output_tmpdir_str)
            input_img_tmpdir_path = Path(input_img_tmpdir_str)
            
            # é«˜é€Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ï¼ˆä¸¦åˆ—ï¼‰
            original_indices_map = {}
            
            def copy_png(png_path: Path) -> Optional[Path]:
                try:
                    original_page_index = int(png_path.stem.split('_')[1]) - 1
                    copied_path = input_img_tmpdir_path / png_path.name
                    shutil.copy2(png_path, copied_path)  # copy2ã¯é«˜é€Ÿ
                    return copied_path, original_page_index
                except Exception:
                    return None
            
            copied_paths = []
            with ThreadPoolExecutor(max_workers=mp.cpu_count()) as executor:
                results = list(executor.map(copy_png, png_paths))
                for result in results:
                    if result:
                        copied_path, original_idx = result
                        copied_paths.append(copied_path)
                        original_indices_map[copied_path.name] = original_idx
            
            if not copied_paths:
                return {}
            
            # YomiTokuå®Ÿè¡Œï¼ˆCPUæœ€é©åŒ–è¨­å®šï¼‰
            cmd = [
                "yomitoku", str(input_img_tmpdir_path),
                "-f", "md", "-o", str(ocr_output_tmpdir_path),
                "--device", device,
                "--combine", "--lite",
                "--batch-size", "4" if device == "cpu" else "8"  # CPUæ™‚ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºå°ã•ã
            ]
            
            try:
                process = subprocess.run(
                    cmd, 
                    check=True, 
                    capture_output=True, 
                    text=True, 
                    encoding='utf-8', 
                    errors='replace',
                    timeout=300  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )
            except subprocess.TimeoutExpired:
                st.error("OCRå‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†ï¼‰")
                return {}
            except subprocess.CalledProcessError as e:
                st.error(f"YomiTokuå®Ÿè¡Œå¤±æ•—: {e.stderr}")
                return {}
            except FileNotFoundError:
                st.error("YomiTokuã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
            
            # çµæœèª­ã¿è¾¼ã¿
            md_files = list(ocr_output_tmpdir_path.glob("*.md"))
            if not md_files:
                return {}
                
            md_text = md_files[0].read_text(encoding="utf-8")
            parts = [s.strip() for s in md_text.split("\n---\n")]
            
            # çµæœãƒãƒƒãƒ”ãƒ³ã‚°
            sorted_names = sorted([p.name for p in copied_paths])
            for i, text_part in enumerate(parts):
                if i < len(sorted_names):
                    png_filename = sorted_names[i]
                    if png_filename in original_indices_map:
                        original_idx = original_indices_map[png_filename]
                        md_by_page[original_idx] = text_part
                          except Exception as e:
        st.error(f"OCRå‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {e}")
        return {}
    
    return md_by_page

# ========================================= è¶…é«˜é€Ÿä¸¦åˆ—PDFå¤‰æ› =========================================

def pdf_to_markdown_ultra_fast(pdf_path: Path, dst_dir: Path, cache_dir: Path, 
                               device: str = "cpu") -> Tuple[str, str]:
    """è¶…é«˜é€ŸPDFå¤‰æ›ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰"""
    start_time = time.time()
    
    try:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€Ÿï¼‰
        pdf_hash = sha256(pdf_path)
        cache_md = cache_dir / f"{pdf_hash}.md"
        out_md = dst_dir / f"{pdf_path.stem}.md"
        
        if cache_md.exists():
            try:
                shutil.copy2(cache_md, out_md)
                elapsed = time.time() - start_time
                return "cached", f"âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ ({elapsed:.2f}ç§’)"
            except Exception:
                pass
        
        # PDFèª­ã¿è¾¼ã¿
        doc = fitz.open(pdf_path)
        total_pages = doc.page_count
        
        # ä¸¦åˆ—ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        def extract_page_text(page_idx: int) -> Tuple[int, str, bool]:
            page = doc.load_page(page_idx)
            has_text = has_text_layer(page)
            if has_text:
                md_text = page_to_md_fast(page)
                return page_idx, md_text, True
            else:
                return page_idx, "", False
        
        # CPUä¸¦åˆ—å‡¦ç†
        max_workers = min(mp.cpu_count(), total_pages, 8)  # æœ€å¤§8ä¸¦åˆ—
        md_pages = [""] * total_pages
        need_ocr_indices = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_idx = {executor.submit(extract_page_text, i): i for i in range(total_pages)}
            for future in as_completed(future_to_idx):
                page_idx, md_text, has_text = future.result()
                if has_text:
                    md_pages[page_idx] = md_text
                else:
                    need_ocr_indices.append(page_idx)
        
        # OCRå‡¦ç†ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
        if need_ocr_indices:
            st.info(f"ğŸ”¬ OCRå®Ÿè¡Œ: {len(need_ocr_indices)}ãƒšãƒ¼ã‚¸")
            
            with tempfile.TemporaryDirectory(prefix="pdf2md_ultra_fast_") as png_temp_dir:
                png_temp_path = Path(png_temp_dir)
                
                # ä¸¦åˆ—ç”»åƒã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                pngs = export_pages_as_png_parallel(
                    doc, need_ocr_indices, 
                    dpi=150,  # é«˜é€ŸåŒ–ã®ãŸã‚ä½DPI
                    outdir=png_temp_path,
                    max_workers=max_workers
                )
                
                if pngs:
                    # OCRå®Ÿè¡Œ
                    ocr_results = run_yomitoku_fast(pngs, device=device)
                    for page_idx, ocr_text in ocr_results.items():
                        if 0 <= page_idx < total_pages:
                            md_pages[page_idx] = ocr_text
        
        # æœ€çµ‚çµæœçµ±åˆ
        final_md = "\n\n---\n\n".join(filter(None, md_pages))
        
        # ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãå‡ºã—
        def write_file(path: Path, content: str) -> bool:
            try:
                path.write_text(content, encoding="utf-8")
                return True
            except:
                return False
        
        with ThreadPoolExecutor(max_workers=2) as executor:
            output_future = executor.submit(write_file, out_md, final_md)
            cache_future = executor.submit(write_file, cache_md, final_md)
            
            output_success = output_future.result()
            cache_future.result()  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯å¤±æ•—ã—ã¦ã‚‚å•é¡Œãªã—
        
        doc.close()
        elapsed = time.time() - start_time
        
        if output_success:
            return "success", f"âœ… å¤‰æ›å®Œäº† ({elapsed:.2f}ç§’)"
        else:
            return "failed", f"âŒ æ›¸ãå‡ºã—å¤±æ•— ({elapsed:.2f}ç§’)"
            
    except Exception as e:
        return "failed", f"âŒ å¤‰æ›å¤±æ•—: {e}"

def process_pdfs_ultra_fast(pdf_paths: List[Path], dst_dir: Path, cache_dir: Path, 
                           device: str = "cpu", progress_callback=None) -> Dict[str, int]:
    """ä¸¦åˆ—PDFä¸€æ‹¬å¤‰æ›"""
    total_files = len(pdf_paths)
    results = {"success": 0, "cached": 0, "failed": 0}
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    try:
        cache_dir.mkdir(parents=True, exist_ok=True)
    except:
        pass
    
    # ä¸¦åˆ—å‡¦ç†ï¼ˆCPUã‚³ã‚¢æ•°ã«åŸºã¥ãï¼‰
    max_workers = min(mp.cpu_count() // 2, 4, total_files)  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è€ƒæ…®
    
    def process_single_pdf(args):
        idx, pdf_path = args
        result, message = pdf_to_markdown_ultra_fast(pdf_path, dst_dir, cache_dir, device)
        return idx, pdf_path.name, result, message
    
    completed = 0
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ã‚¿ã‚¹ã‚¯æå‡º
        future_to_args = {
            executor.submit(process_single_pdf, (i, pdf_path)): (i, pdf_path) 
            for i, pdf_path in enumerate(pdf_paths)
        }
        
        # çµæœåé›†
        for future in as_completed(future_to_args):
            idx, filename, result, message = future.result()
            results[result] += 1
            completed += 1
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
            if progress_callback:
                progress_value = completed / total_files
                progress_callback(progress_value, f"{message} | {filename} ({completed}/{total_files})")
            
            # ãƒ­ã‚°å‡ºåŠ›
            if result == "success":
                st.success(message + f" | {filename}")
            elif result == "cached":
                st.info(message + f" | {filename}")
            else:
                st.error(message + f" | {filename}")
    
    return results
                process = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
            except subprocess.CalledProcessError as e:
                st.error(f"YomiTokuã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
                st.error(f"ã‚¨ãƒ©ãƒ¼å‡ºåŠ›:\n{e.stderr}")
                return {}
            except FileNotFoundError:
                st.error("YomiTokuã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ã€PATHãŒé€šã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return {}

            md_files = list(ocr_output_tmpdir_path.glob("*.md"))
            if not md_files:
                st.warning("YomiTokuã«ã‚ˆã‚‹OCRçµæœã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return {}
                
            md_text = md_files[0].read_text(encoding="utf-8")
            # YomiToku combine å‡ºåŠ›ã¯ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šã« '---' ã‚’ä½¿ã†
            parts = [s.strip() for s in md_text.split("\\n---\\n")] # Adjusted split pattern
            
            # Sort the copied PNG names to match the order of 'parts' from YomiToku's combined output
            sorted_copied_png_names = sorted([p.name for p in copied_png_paths_for_yomitoku])

            if len(parts) != len(sorted_copied_png_names):
                st.warning(f"OCRçµæœã®ãƒ‘ãƒ¼ãƒ„æ•°({len(parts)})ã¨ç”»åƒæ•°({len(sorted_copied_png_names)})ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚å‡¦ç†çµæœãŒä¸æ­£ç¢ºã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                # Attempt to process what we can, or return {}
            
            for i, text_part in enumerate(parts):
                if i < len(sorted_copied_png_names):
                    png_filename = sorted_copied_png_names[i]
                    if png_filename in original_indices_map:
                        original_idx = original_indices_map[png_filename]
                        md_by_page[original_idx] = text_part
                    else:
                        st.warning(f"OCRçµæœã®ãƒ•ã‚¡ã‚¤ãƒ«å {png_filename} ã«å¯¾å¿œã™ã‚‹å…ƒã®ãƒšãƒ¼ã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    # More parts than images, something is wrong
                    st.warning(f"OCRçµæœã®ãƒ‘ãƒ¼ãƒ„ãŒç”»åƒæ•°ã‚ˆã‚Šå¤šã„ã§ã™ã€‚ãƒ‘ãƒ¼ãƒ„ {i+1} ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚")
                    break 
    except Exception as e:
        st.error(f"OCRå‡¦ç†ä¸­ï¼ˆä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ãªã©ï¼‰ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        return {} # Return empty if any critical error in temp dir handling
    return md_by_page

# --------- 3. å˜ä¸€ PDF å¤‰æ› (ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ã‚’å¼·åŒ–) --------
def pdf_to_markdown(pdf_path: Path,
                    dst_dir: Path,
                    cache_dir: Path,
                    device: str = "cuda",
                    progress_bar=None,
                    file_idx=0,
                    total_files=1
                    ) -> None:
    if progress_bar:
        progress_text = f"å‡¦ç†ä¸­: {pdf_path.name} ({file_idx+1}/{total_files})"
        try:
            progress_value = (file_idx / total_files) if total_files > 0 else 0
            progress_bar.progress(progress_value, text=progress_text)
        except Exception as e:
            st.warning(f"ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°ã«å¤±æ•—: {e}")


    pdf_hash = sha256(pdf_path)
    cache_md = cache_dir / f"{pdf_hash}.md"
    out_md  = dst_dir / f"{pdf_path.stem}.md"

    try:
        cache_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ/ç¢ºèªã«å¤±æ•— ({cache_dir}): {e}")
        # Continue without cache if it fails

    if cache_md.exists():
        try:
            shutil.copy(cache_md, out_md)
            st.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ã—ã¾ã—ãŸ: {pdf_path.name} -> {out_md.name}")
            if progress_bar:
                 new_progress = ((file_idx + 1) / total_files) if total_files > 0 else 1
                 progress_bar.progress(new_progress, text=f"å®Œäº† (ã‚­ãƒ£ãƒƒã‚·ãƒ¥): {pdf_path.name} ({file_idx+1}/{total_files})")
            return
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•— ({cache_md} -> {out_md}): {e}ã€‚é€šå¸¸å¤‰æ›ã‚’è©¦ã¿ã¾ã™ã€‚")

    doc = None
    try:
        doc = fitz.open(pdf_path)
    except Exception as e:
        st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ: {pdf_path.name} - {e}")
        if progress_bar:
            new_progress = ((file_idx + 1) / total_files) if total_files > 0 else 1
            progress_bar.progress(new_progress, text=f"ã‚¨ãƒ©ãƒ¼: {pdf_path.name} ({file_idx+1}/{total_files})")
        return

    md_pages = [page_to_md(p) for p in doc] # Initial conversion from text layer
    need_ocr_pages_indices = [i for i,p in enumerate(doc) if not has_text_layer(p)]

    if need_ocr_pages_indices:
        st.write(f"{pdf_path.name}: {len(need_ocr_pages_indices)} ãƒšãƒ¼ã‚¸ã§OCRã‚’å®Ÿè¡Œã—ã¾ã™...")
        png_export_temp_dir = None # Initialize
        try:
            png_export_temp_dir = Path(tempfile.mkdtemp(prefix="pdf2md_gui_png_export_"))
            pngs  = export_pages_as_png(doc, need_ocr_pages_indices, dpi=220, outdir=png_export_temp_dir)
            if pngs: # If any PNGs were successfully exported
                 ocr_md_parts = run_yomitoku(pngs, device=device)
                 for idx_in_doc, md_text_part in ocr_md_parts.items():
                     if 0 <= idx_in_doc < len(md_pages): # Check index bounds
                         md_pages[idx_in_doc] = md_text_part # Overwrite with OCR text
                     else:
                         st.warning(f"OCRçµæœã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {idx_in_doc} ãŒãƒšãƒ¼ã‚¸ç¯„å›²å¤–ã§ã™ ({pdf_path.name})ã€‚")
            else:
                st.warning(f"{pdf_path.name}: OCRå¯¾è±¡ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã€ã¾ãŸã¯å¯¾è±¡ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        except Exception as e:
            st.error(f"OCRå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ ({pdf_path.name}): {e}")
        finally:
            if png_export_temp_dir and png_export_temp_dir.exists():
                try:
                    shutil.rmtree(png_export_temp_dir)
                except Exception as e:
                    st.warning(f"PNGã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤ã«å¤±æ•— ({png_export_temp_dir}): {e}")
            
    final_md = "\\n\\n---\\n\\n".join(md_pages) # Page separator for final markdown
    try:
        out_md.write_text(final_md, encoding="utf-8")
        try:
            # Attempt to save to cache even if main write succeeds
            cache_md.write_text(final_md, encoding="utf-8")
        except Exception as e:
            st.warning(f"Markdownã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã«å¤±æ•— ({cache_md}): {e}")
        st.success(f"å¤‰æ›å®Œäº†: {pdf_path.name} -> {out_md.name}")
    except Exception as e:
        st.error(f"Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãå‡ºã—ã«å¤±æ•— ({out_md}): {e}")
        if progress_bar:
            new_progress = ((file_idx + 1) / total_files) if total_files > 0 else 1
            progress_bar.progress(new_progress, text=f"ã‚¨ãƒ©ãƒ¼(æ›¸ãå‡ºã—å¤±æ•—): {pdf_path.name} ({file_idx+1}/{total_files})")
        # Ensure doc is closed even if write fails, if it was opened
        if doc:
            doc.close()
        return

    if progress_bar:
        new_progress = ((file_idx + 1) / total_files) if total_files > 0 else 1
        progress_bar.progress(new_progress, text=f"å®Œäº†: {pdf_path.name} ({file_idx+1}/{total_files})")
    
    if doc: # Close the document
        doc.close()

# --------- 4. Streamlit GUI -------------------------------------------------

def select_folder_dialog():
    """ãƒ•ã‚©ãƒ«ãƒ€é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ãã€é¸æŠã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’è¿”ã™"""
    root = tk.Tk()
    root.withdraw()  # Tkinterã®ãƒ¡ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¡¨ç¤ºã—ãªã„
    root.attributes('-topmost', True)  # ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’æœ€å‰é¢ã«è¡¨ç¤º
    folder_selected = filedialog.askdirectory()
    root.destroy()
    return folder_selected

st.set_page_config(page_title="PDF to Markdown Converter", layout="wide")
st.title("ğŸ“„ PDF to Markdown ä¸€æ‹¬å¤‰æ›ãƒ„ãƒ¼ãƒ«")

st.sidebar.header("è¨­å®š")
uploaded_files = st.sidebar.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (è¤‡æ•°å¯)", type="pdf", accept_multiple_files=True)

st.sidebar.markdown("---")
st.sidebar.subheader("ã¾ãŸã¯ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®š")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’ç®¡ç†
if 'folder_path_for_text_input' not in st.session_state:
    st.session_state.folder_path_for_text_input = ""

if st.sidebar.button("ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãƒ‘ã‚¹ã‚’å…¥åŠ›", key="select_folder_button"):
    selected_path = select_folder_dialog()
    if selected_path:
        st.session_state.folder_path_for_text_input = selected_path
    # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ä¸€åº¦ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã«åæ˜ ã•ã›ã‚‹
    st.rerun()


folder_path_str = st.sidebar.text_input(
    "PDFãŒå«ã¾ã‚Œã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›",
    value=st.session_state.folder_path_for_text_input, # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰å€¤ã‚’å–å¾—
    help="ä¸Šã®ãƒœã‚¿ãƒ³ã§é¸æŠã™ã‚‹ã‹ã€ã“ã“ã«ç›´æ¥ãƒ‘ã‚¹ã‚’å…¥åŠ›ã¾ãŸã¯è²¼ã‚Šä»˜ã‘ã—ã¦ãã ã•ã„ã€‚ä¾‹: D:\\\\scanned_documents (ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚‚æ¤œç´¢ã—ã¾ã™)"
)

# --- å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€é¸æŠ ---
st.sidebar.markdown("---") # åŒºåˆ‡ã‚Šç·š
st.sidebar.subheader("å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€")

if 'dst_folder_path' not in st.session_state:
    st.session_state.dst_folder_path = str(Path.home() / "Documents" / "pdf2md_output") # åˆæœŸå€¤ã‚’è¨­å®š

if st.sidebar.button("å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ", key="select_dst_folder_button"):
    selected_dst_path = select_folder_dialog()
    if selected_dst_path:
        st.session_state.dst_folder_path = selected_dst_path
    st.rerun()

# é¸æŠã•ã‚ŒãŸå‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’è¡¨ç¤º (ç·¨é›†ä¸å¯)
st.sidebar.caption(f"ç¾åœ¨ã®å‡ºåŠ›å…ˆ: {st.session_state.dst_folder_path}")


device_options = ["cpu"]
if shutil.which("nvidia-smi"): # Check if nvidia-smi (CUDA utility) is available
    device_options.insert(0, "cuda") # Add cuda as first option if available
device_default_index = 0 # Default to first option (cuda if available, else cpu)

device = st.sidebar.selectbox("OCRãƒ‡ãƒã‚¤ã‚¹", device_options, index=device_default_index) 

cache_dir = Path(".mdcache_gui") # GUI-specific cache directory

if st.sidebar.button("å¤‰æ›é–‹å§‹", type="primary", key="start_conversion_button"):
    pdf_paths_to_process = []
    source_type = None

    # folder_path_str ã« st.session_state ã®æœ€æ–°å€¤ã‚’ä»£å…¥ã—ç›´ã™ (ãƒœã‚¿ãƒ³çµŒç”±ã®å ´åˆã‚’è€ƒæ…®)
    current_folder_path_from_input = folder_path_str

    # 1. Determine the source of PDF files
    if current_folder_path_from_input: # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’ä½¿ç”¨
        # folder_path = Path(folder_path_str) # Keep for rglob, but check with os.path.isdir
        if os.path.isdir(current_folder_path_from_input): # Use os.path.isdir for initial validation
            folder_path = Path(current_folder_path_from_input) # Convert to Path after validation for rglob
            # Use rglob for recursive search and sort the results
            pdf_paths_to_process = sorted(list(folder_path.rglob("*.pdf")))
            if not pdf_paths_to_process:
                st.warning(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ '{current_folder_path_from_input}' (ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å«ã‚€) ã«PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                st.stop() # Use st.stop() to halt execution cleanly
            source_type = "folder"
            st.info(f"ãƒ•ã‚©ãƒ«ãƒ€ '{current_folder_path_from_input}' å†…ã®PDFã‚’å‡¦ç†ã—ã¾ã™ ({len(pdf_paths_to_process)}ä»¶)ã€‚")
        else:
            st.error(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ '{current_folder_path_from_input}' ã¯æœ‰åŠ¹ãªãƒ•ã‚©ãƒ«ãƒ€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()
    elif uploaded_files:
        source_type = "upload"
        st.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ {len(uploaded_files)}å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
    else:
        st.sidebar.warning("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ã‹ã€ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # 2. Validate destination directory
    dst_dir_str = st.session_state.dst_folder_path # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰å–å¾—
    if not dst_dir_str:
        st.sidebar.error("å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚") # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›´
        st.stop()
    dst_dir = Path(dst_dir_str)
    try:
        dst_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        st.error(f"å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•—: {dst_dir} - {e}")
        st.stop()

    # 3. Setup cache
    try:
        cache_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•— ({cache_dir}): {e}")
    
    st.info(f"å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€: {dst_dir}")
    st.info(f"OCRãƒ‡ãƒã‚¤ã‚¹: {device}")

    # 4. Process PDFs
    progress_bar_area = st.empty() # Placeholder for the progress bar

    if source_type == "upload":
        # Use a context manager for the temporary directory for uploads
        with tempfile.TemporaryDirectory(prefix="pdf2md_gui_upload_") as upload_tmpdir_str:
            upload_tmpdir_path = Path(upload_tmpdir_str)
            temp_pdf_paths_from_upload = [] # Store paths of successfully saved temp files
            for uploaded_file_data in uploaded_files:
                try:
                    temp_pdf_path = upload_tmpdir_path / uploaded_file_data.name
                    with open(temp_pdf_path, "wb") as f:
                        f.write(uploaded_file_data.getbuffer())
                    temp_pdf_paths_from_upload.append(temp_pdf_path)
                except Exception as e:
                    st.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file_data.name} ã®ä¸€æ™‚ä¿å­˜å¤±æ•—: {e}")
            
            if not temp_pdf_paths_from_upload: # If no files were successfully saved
                st.error("å‡¦ç†å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆä¸€æ™‚ä¿å­˜å¤±æ•—ï¼‰ã€‚")
                progress_bar_area.empty() # Clear progress bar area
                st.stop()
            
            pdf_paths_to_process = temp_pdf_paths_from_upload # Update the list to process    # This block will now execute for both 'folder' and 'upload' (after uploads are prepared)
    if pdf_paths_to_process: # Ensure there are files to process
        total_files = len(pdf_paths_to_process)
        progress_bar = progress_bar_area.progress(0, text=f"æº–å‚™ä¸­... (0/{total_files})")
        
        # Progress callback function
        def progress_callback(current: int, total: int, file_name: str):
            progress = current / total if total > 0 else 1
            progress_bar.progress(progress, text=f"å‡¦ç†ä¸­: {file_name} ({current}/{total})")
        
        # Use the ultra-fast parallel processing function
        results = process_pdfs_ultra_fast(pdf_paths_to_process, dst_dir, cache_dir, device, progress_callback)
        
        progress_bar_area.empty() # Clear progress bar after completion
        st.balloons()
        st.success(f"ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ({total_files}ä»¶å‡¦ç†)")
    else:
        # This case should ideally be caught earlier, but as a fallback:
        st.warning("å‡¦ç†å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


st.markdown("---")
st.markdown("""
### ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ
1.  å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€å€‹åˆ¥ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ã‹ã€PDFãŒå«ã¾ã‚Œã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚
    ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ãŸå ´åˆã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚ï¼‰
2.  Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®šã—ã¾ã™ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆã•ã‚Œã¾ã™ï¼‰ã€‚
3.  OCRã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã‚’é¸æŠã—ã¾ã™ï¼ˆCUDAå¯¾å¿œGPUãŒã‚ã‚Œã° `cuda` ã‚’ã€ãªã‘ã‚Œã° `cpu` ã‚’é¸æŠï¼‰ã€‚
4.  ã€Œå¤‰æ›é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€å‡¦ç†ãŒå§‹ã¾ã‚Šã¾ã™ã€‚
""")

# To run this script: streamlit run your_script_name.py
# Ensure Typer related app.run() or similar is removed if this was converted from a Typer CLI.
# The main execution flow is now handled by Streamlit's rendering of the script from top to bottom.